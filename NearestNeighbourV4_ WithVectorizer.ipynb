{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn import cross_validation\n",
    "import heapq\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "st = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line count in training : 800\n",
      "Line count in format : 350\n",
      "Line count in test : 350\n"
     ]
    }
   ],
   "source": [
    "with open(\"test/train.dat\", \"r\") as fh:\n",
    "    linesOfTrainData = fh.readlines()\n",
    "print(\"Line count in training :\" ,len(linesOfTrainData))\n",
    "\n",
    "#with open(\"TestData/format.dat\", \"r\") as fh:\n",
    "with open(\"test/format.dat\", \"r\") as fh:\n",
    "    linesOfFormat = fh.readlines()\n",
    "print(\"Line count in format :\" ,len(linesOfFormat))\n",
    "\n",
    "with open(\"test/test.dat\", \"r\") as fh:\n",
    "    linesOfTestData = fh.readlines()\n",
    "print(\"Line count in test :\" ,len(linesOfTestData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " #vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 50, stop_words = 'english', vocabulary=features)\n",
    "  \n",
    "vectorizer = CountVectorizer(analyzer='word', lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 88110)\t1\n",
      "  (0, 87805)\t1\n",
      "  (0, 87796)\t1\n",
      "  (0, 87697)\t1\n",
      "  (0, 87478)\t1\n",
      "  (0, 87451)\t1\n",
      "  (0, 87389)\t1\n",
      "  (0, 87316)\t1\n",
      "  (0, 87250)\t1\n",
      "  (0, 87091)\t1\n",
      "  (0, 86964)\t1\n",
      "  (0, 86787)\t1\n",
      "  (0, 86714)\t1\n",
      "  (0, 86673)\t1\n",
      "  (0, 86537)\t1\n",
      "  (0, 86414)\t1\n",
      "  (0, 86369)\t1\n",
      "  (0, 86352)\t1\n",
      "  (0, 86331)\t1\n",
      "  (0, 86199)\t1\n",
      "  (0, 86114)\t1\n",
      "  (0, 86082)\t1\n",
      "  (0, 85352)\t1\n",
      "  (0, 85208)\t1\n",
      "  (0, 85144)\t1\n",
      "  :\t:\n",
      "  (0, 32920)\t1\n",
      "  (0, 31940)\t1\n",
      "  (0, 31138)\t1\n",
      "  (0, 27601)\t1\n",
      "  (0, 25102)\t1\n",
      "  (0, 25022)\t1\n",
      "  (0, 22607)\t1\n",
      "  (0, 21017)\t1\n",
      "  (0, 18974)\t1\n",
      "  (0, 18122)\t1\n",
      "  (0, 17823)\t1\n",
      "  (0, 15745)\t1\n",
      "  (0, 15657)\t1\n",
      "  (0, 15365)\t1\n",
      "  (0, 12518)\t1\n",
      "  (0, 7127)\t1\n",
      "  (0, 4619)\t1\n",
      "  (0, 3044)\t1\n",
      "  (0, 2162)\t1\n",
      "  (0, 1994)\t1\n",
      "  (0, 59823)\t1\n",
      "  (0, 52283)\t1\n",
      "  (0, 50318)\t1\n",
      "  (0, 26104)\t1\n",
      "  (0, 8901)\t1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linesOfTrainData_Transformed = vectorizer.fit_transform(linesOfTrainData)\n",
    "print(linesOfTrainData_Transformed[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 85)\t1\n",
      "  (0, 95)\t1\n",
      "  (0, 160)\t1\n",
      "  (0, 178)\t1\n",
      "  (0, 193)\t1\n",
      "  (0, 242)\t1\n",
      "  (0, 319)\t1\n",
      "  (0, 655)\t1\n",
      "  (0, 1096)\t1\n",
      "  (0, 1144)\t1\n",
      "  (0, 1225)\t1\n",
      "  (0, 1303)\t1\n",
      "  (0, 1379)\t1\n",
      "  (0, 1429)\t1\n",
      "  (0, 1533)\t1\n",
      "  (0, 1595)\t1\n",
      "  (0, 1713)\t1\n",
      "  (0, 1726)\t1\n",
      "  (0, 1819)\t1\n",
      "  (0, 1849)\t1\n",
      "  (0, 2010)\t1\n",
      "  (0, 2144)\t1\n",
      "  (0, 2286)\t1\n",
      "  (0, 2344)\t1\n",
      "  (0, 2565)\t1\n",
      "  :\t:\n",
      "  (0, 85596)\t1\n",
      "  (0, 85699)\t1\n",
      "  (0, 85774)\t1\n",
      "  (0, 86341)\t1\n",
      "  (0, 86368)\t1\n",
      "  (0, 86558)\t1\n",
      "  (0, 86573)\t1\n",
      "  (0, 86696)\t1\n",
      "  (0, 86813)\t1\n",
      "  (0, 86844)\t1\n",
      "  (0, 86868)\t1\n",
      "  (0, 86978)\t1\n",
      "  (0, 87043)\t1\n",
      "  (0, 87087)\t1\n",
      "  (0, 87273)\t1\n",
      "  (0, 87436)\t1\n",
      "  (0, 87511)\t1\n",
      "  (0, 87689)\t1\n",
      "  (0, 87695)\t1\n",
      "  (0, 87731)\t1\n",
      "  (0, 87773)\t1\n",
      "  (0, 87881)\t1\n",
      "  (0, 87937)\t1\n",
      "  (0, 87966)\t1\n",
      "  (0, 87974)\t1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linesOfTestData_Transformed = vectorizer.transform(linesOfTestData)\n",
    "print(linesOfTestData_Transformed[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names() \n",
    "len(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def CalculateCosine(vt,vs):\n",
    "        cosineSimilarityValue = cosine_similarity(vt,vs)\n",
    "        return cosineSimilarityValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cosineSimilarityValue = CalculateCosine(linesOfTestData_Transformed,linesOfTrainData_Transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count :  350\n",
      "--The End--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = open('test/testData/format.dat', 'w')\n",
    "count = 0\n",
    "for row in cosineSimilarityValue:\n",
    "\n",
    "    \n",
    "    #kneighbours = heapq.nlargest(5, row)\n",
    "    k=42\n",
    "    partitioned_row_byindex = np.argpartition(-row, k)  \n",
    "    similar_index = partitioned_row_byindex[:k]\n",
    "    \n",
    "    #print(similar_index)\n",
    "    \n",
    "    neighbourReviewTypeList = []\n",
    "    neighbourReviewTypeNegative = 0\n",
    "    neighbourReviewTypePositive = 0\n",
    "\n",
    "    for index in similar_index:\n",
    "\n",
    "        if linesOfTrainData[index].strip()[0] == '0':\n",
    "            #neighbourReviewTypeList.append(\"-1\")\n",
    "            neighbourReviewTypeNegative+=1\n",
    "        elif linesOfTrainData[index].strip()[0] == '1':\n",
    "            #neighbourReviewTypeList.append(\"+1\")\n",
    "            neighbourReviewTypePositive+=1\n",
    "            \n",
    "    \n",
    "    if neighbourReviewTypeNegative > neighbourReviewTypePositive:\n",
    "        f.write('0\\n')\n",
    "        count+=1\n",
    "    else:\n",
    "        f.write('1\\n')\n",
    "        count+=1\n",
    "\n",
    "print(\"count : \",count)\n",
    "print(\"--The End--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
